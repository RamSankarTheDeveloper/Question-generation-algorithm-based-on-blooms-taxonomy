import spacy
nlp = spacy.load("en_core_web_sm")

#preprocessing:-after dividing into sentences, divide into tokens
sent = "James is playing football in the stadium at 8pm"
def dep_conversion():
    global subj,aux_verb,root_verb,obj,sent_list #need to remove globals
    subj,aux_verb,root_verb,obj,sent_list = [],[],[],[],[] #dep lists
    doc = nlp(sent)
    for token in doc:
      sent_list.append(token.text)
      print(token.dep_)
      if ((token.dep_  in ["nsubjpass",'csubjpass','nsubj','csubj']) and (not subj)) :
        subj = token.text
      elif (token.dep_ in ["ROOT","root"] and (not root_verb)):
        root_verb = token.text
      elif ((token.dep_ not in ["auxpass","AUX","MD","BES"]) and (not aux_verb)):
        aux_verb = token.text
      elif ((token.dep_ not in ["dobj",'iobj','oprd','obj',"pobj"]) and (not obj)):
        obj = token.text
  
#without coref and ent 
def check_dep_conversion(dep_list):
    for item in sent_list:
      if item in dep_list:
        print("who")
      else:
        print(item)
    print("---")

#with ent not coref
def ent_conversion():
    global ent_label_list,ent_text_list
    ent_label_list,ent_text_list=[],[]
    for entities in doc.ents:
        #print(f"{entities.text:<25} {entities.label_:<15} {spacy.explain(entities.label_)}")
        ent_text_list.append(entities.text)
        ent_label_list.append(entities.label_)
    return ent_label_list,ent_text_list

"""if item in entity list is present in subj/verb/obj,
          then assign appropriate wh-question"""
def check_ent_conversion():
  for item in ent_text_list:
    if item in (subj or aux_verb or root_verb or obj or sent_list):
      print(item)
