{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVdIW9s3N5qR"
      },
      "outputs": [],
      "source": [
        "\n",
        "#date:21/02/2023\n",
        "############################\n",
        "#https://youtu.be/Sp6jZFHI02Y\n",
        "!git clone https://github.com/huggingface/neuralcoref.git \n",
        "import os\n",
        "os.chdir(\"/content/neuralcoref\")\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .  #'.' is reqd\n",
        "#######################\n",
        "!pip install spacy==2.3.0 \n",
        "import spacy #after restarting the kernel\n",
        "print(spacy. __version__)\n",
        "######################\n",
        "import spacy.cli \n",
        "spacy.cli.download(\"en\")\n",
        "#so that \"en\" works\n",
        "#OSError: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.\n",
        "#https://stackoverflow.com/questions/62822737/oserror-e050-cant-find-model-de-it-doesnt-seem-to-be-a-shortcut-link-a\n",
        "######################\n",
        "# Load your usual SpaCy model (one of SpaCy English models)\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "# Add neural coref to SpaCy's pipe\n",
        "import neuralcoref\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "# You're done. You can now use NeuralCoref as you usually manipulate a SpaCy document annotations.\n",
        "#doc = nlp(text)\n",
        "\n",
        "#edited_text = doc._.coref_resolved\n",
        "#nouns = doc._.coref_clusters\n",
        "#return edited_text, noun"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VbeuqGbew9vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "nlp1 = spacy.load(\"en_core_web_sm\")\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "lRmG8HO-4Xoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class preprocess:\n",
        "  def __init__(self,text):\n",
        "    self.text=text\n",
        "\n",
        "  def paragraph_to_sentences(self):\n",
        "    doc=nlp1(self.text)\n",
        "    sentences=[]\n",
        "    for sent in doc.sents:\n",
        "      sentences.append(sent)\n",
        "    return sentences\n",
        "\n",
        "  def noun_phrases(self,sentence):\n",
        "    doc =nlp1(sentence)\n",
        "    a=[]\n",
        "    for np in doc.noun_chunks:\n",
        "      a.append(np.text)\n",
        "    return a\n",
        "\n",
        "  def tokens(self,sentence):\n",
        "    token = word_tokenize(sentence)\n",
        "    return token\n",
        "\n",
        "  def stopwords(self,sentence):\n",
        "    sp=spacy.load(\"en_core_web_sm\")\n",
        "    all_stopwords = sp.Defaults.stop_words\n",
        "    text_tokens = word_tokenize(sentence)\n",
        "    tokens_without_sw= [word for word in text_tokens if not word in all_stopwords]\n",
        "    return tokens_without_sw\n",
        "\n",
        "  def base_words(self,sentence):\n",
        "    a=[]\n",
        "    doc=nlp1(sent)\n",
        "    for token in doc:\n",
        "      a.append(token.lemma_)\n",
        "    for i in range(len(a)):\n",
        "      a[i]=pst.stem(a[i])\n",
        "    return a\n",
        "    \n",
        "  def lower(self,list1):\n",
        "    for i in range(len(list1)):\n",
        "      list1[i]=list1[i].lower()\n",
        "    return list1\n",
        "\n",
        "  def coref(text): \n",
        "    #change it into different versions\n",
        "    #https://stackoverflow.com/questions/6570635/installing-multiple-versions-of-a-package-with-pip\n",
        "    doc = nlp(text)\n",
        "    edited_text = doc._.coref_resolved\n",
        "    nouns = doc._.coref_clusters\n",
        "    return edited_text, nouns\n",
        "  \n",
        "obj1=preprocess(\"Batman is a vigilante.He owns Wayne enterprises\")#minor:eliminate dots at the end if\n",
        "sentences=obj1.paragraph_to_sentences()\n",
        "print(sentences[0])\n",
        "sent=\"There are good people and bad people in This world who are waiting, waits, given, gave, giving\"\n",
        "phrases=obj1.noun_phrases(sent)\n",
        "tokens=obj1.tokens(sent)\n",
        "stopwords=obj1.stopwords(sent)\n",
        "base_words=obj1.base_words(sent)\n",
        "a=['ksdfDSFSDF','SDFDSF']\n",
        "lower=obj1.lower(a)\n",
        "print(lower)\n",
        "text=\"Batman is a vigilante.He owns Wayne enterprises\"\n",
        "a,b= coref(text)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jFWCQPw4ZtP",
        "outputId": "acb33edf-3214-4461-8822-cf00d6a88564"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batman is a vigilante.\n",
            "['ksdfdsfsdf', 'sdfdsf']\n",
            "Batman is a vigilante.Batman owns Wayne enterprises\n",
            "[Batman: [Batman, He]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vF9dnQ-05tZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}